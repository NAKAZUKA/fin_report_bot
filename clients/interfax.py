# ‚úÖ clients/interfax.py
import httpx
from datetime import datetime
from typing import Optional
from pydantic import BaseModel
from loguru import logger

from utils.token_storage import (
    load_token_from_file,
    save_token_to_file,
    is_token_expired,
)
from db import has_event_been_processed


class TokenResponse(BaseModel):
    token: str
    expirationDate: Optional[datetime]


class InterfaxClient:
    BASE_URL = "https://gateway.e-disclosure.ru/api/v1"
    CHUNK_SIZE = 10_000_000

    def __init__(self, login: str, password: str):
        self._login = login
        self._password = password
        self._client = httpx.AsyncClient(timeout=60.0)
        self._token: Optional[str] = None

    async def init(self):
        self._token = await self.get_token()

    async def _authorize(self) -> str:
        logger.info("üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –≤ –ò–Ω—Ç–µ—Ä—Ñ–∞–∫—Å API...")
        response = await self._client.post(
            f"{self.BASE_URL}/auth",
            json={"login": self._login, "password": self._password}
        )
        response.raise_for_status()
        data = TokenResponse.model_validate(response.json())
        save_token_to_file(data.token, data.expirationDate.isoformat())
        self._token = data.token
        logger.success(f"‚úÖ –¢–æ–∫–µ–Ω –ø–æ–ª—É—á–µ–Ω. –î–µ–π—Å—Ç–≤—É–µ—Ç –¥–æ {data.expirationDate}")
        return self._token

    async def get_token(self) -> str:
        token, exp_str = load_token_from_file()

        if not token or is_token_expired(exp_str):
            return await self._authorize()

        self._token = token
        return self._token

    async def get_file_events(self, subject_code: str, count: int = 100) -> list[dict]:
        token = await self.get_token()
        headers = {"APIKey": token}
        params = {
            "entity": "Files",
            "subjectCode": [subject_code],
            "count": count
        }
        response = await self._client.get(
            f"{self.BASE_URL}/disclosure/events", headers=headers, params=params
        )
        response.raise_for_status()
        events = response.json()

        today = datetime.utcnow().date()
        filtered = []
        for event in events:
            if has_event_been_processed(event["uid"]):
                continue
            file = event.get("file")
            if not file or not file.get("publicUrl"):
                continue

            attrs = {a["name"]: a["value"] for a in file.get("attributes", [])}
            file["attributes"] = attrs

            pub_date_str = attrs.get("DatePub")
            if not pub_date_str:
                continue

            try:
                pub_date = datetime.strptime(pub_date_str, "%d.%m.%Y").date()
            except ValueError:
                continue

            if pub_date != today:
                continue

            filtered.append(event)
        return filtered

    async def probe_company_info(self, subject_code: str) -> dict | None:
        token = await self.get_token()
        headers = {"APIKey": token}
        params = {
            "entity": "Files",
            "subjectCode": [subject_code],
            "count": 1
        }
        response = await self._client.get(
            f"{self.BASE_URL}/disclosure/events", headers=headers, params=params
        )
        response.raise_for_status()
        events = response.json()

        for event in events:
            subject = event.get("subject")
            if subject:
                return subject
        return None

    async def search_reports_by_category(self, subject_code: str, category_name: str, year: int, count: int = 100) -> list[dict]:
        token = await self.get_token()
        headers = {"APIKey": token}
        params = {
            "entity": "Files",
            "subjectCode": [subject_code],
            "count": count
        }
        response = await self._client.get(f"{self.BASE_URL}/disclosure/events", headers=headers, params=params)
        response.raise_for_status()
        events = response.json()

        results = []
        for event in events:
            file = event.get("file", {})
            if not file or not file.get("publicUrl"):
                continue
            category = file.get("category", {}).get("name", "").lower()
            if category_name.lower() not in category:
                continue
            attrs = {a["name"]: a["value"] for a in file.get("attributes", [])}
            file["attributes"] = attrs
            if str(year) != attrs.get("YearRep", ""):
                continue
            results.append(event)
        return results
    
    async def close(self):
        await self._client.aclose()

    async def download_file(self, file_data: dict) -> bytes:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –∏–∑ –ò–Ω—Ç–µ—Ä—Ñ–∞–∫—Å API –ª–∏–±–æ –ø–æ UID, –ª–∏–±–æ –ø–æ publicUrl.
        –û—Ç–¥–∞—ë—Ç –±–∞–π—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å PDF.
        """
        token = await self.get_token()
        user_agent = {"User-Agent": "Mozilla/5.0"}
        headers = {"APIKey": token, **user_agent}

        file_uid = file_data.get("uid")
        public_url = file_data.get("publicUrl")

        if not file_uid and not public_url:
            raise ValueError("‚ùå –ù–µ—Ç –Ω–∏ UID, –Ω–∏ publicUrl ‚Äî –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª")

        file_url = f"{self.BASE_URL}/disclosure/download/files/{file_uid}" if file_uid else None

        # üß™ –ü—Ä–æ–±—É–µ–º —Å–Ω–∞—á–∞–ª–∞ —Å–∫–∞—á–∞—Ç—å –ø–æ UID —á–µ—Ä–µ–∑ Range-–∑–∞–ø—Ä–æ—Å—ã
        if file_url:
            try:
                head_resp = await self._client.head(file_url, headers=headers)
                if head_resp.status_code == 404:
                    logger.warning("‚ö†Ô∏è –§–∞–π–ª –ø–æ UID –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ publicUrl.")
                    raise FileNotFoundError()

                head_resp.raise_for_status()
                total_size = int(head_resp.headers.get("Content-Length", "0"))
                logger.info(f"üì¶ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {total_size} –±–∞–π—Ç")

                chunks = []
                downloaded = 0
                attempt = 1
                while downloaded < total_size:
                    start = downloaded
                    end = min(start + self.CHUNK_SIZE - 1, total_size - 1)
                    range_header = {"Range": f"bytes={start}-{end}"}
                    logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞: bytes={start}-{end}")

                    resp = await self._client.get(file_url, headers={**headers, **range_header})
                    resp.raise_for_status()

                    chunks.append(resp.content)
                    downloaded += len(resp.content)
                    attempt += 1

                full_content = b"".join(chunks)
                if len(full_content) != total_size:
                    logger.warning("‚ö†Ô∏è –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å Content-Length")
                return full_content

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø–æ UID: {e}. –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ publicUrl...")

        # üîÑ Fallback: –∑–∞–≥—Ä—É–∑–∫–∞ —á–µ—Ä–µ–∑ publicUrl
        try:
            resp = await self._client.get(public_url, headers=user_agent, follow_redirects=True)
            resp.raise_for_status()
            content_type = resp.headers.get("Content-Type", "")
            if "application/pdf" not in content_type.lower():
                logger.warning(f"‚ö†Ô∏è –ù–µ PDF-—Ñ–∞–π–ª. Content-Type: {content_type}")
                raise ValueError("–ü–æ–ª—É—á–µ–Ω –Ω–µ PDF-—Ñ–∞–π–ª. –ü—É–±–ª–∏–∫–∞—Ü–∏—è –º–æ–≥–ª–∞ –±—ã—Ç—å —É–¥–∞–ª–µ–Ω–∞.")
            return resp.content
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –ø–æ publicUrl: {e}")
            raise
